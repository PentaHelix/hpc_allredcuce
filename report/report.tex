\documentclass[twoside,twocolumn,hidelinks]{article}

\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\linespread{1.05} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics

\usepackage[english]{babel} % Language hyphenation and typographical rules
\usepackage[normalem]{ulem}

\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} % Document margins
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables\usepackage[backend=biber]{biblatex}

\usepackage{enumitem} % Customized lists
\usepackage{tikz-qtree}
\usepackage{tree-dvips}
\setlist[itemize]{noitemsep} % Make itemize lists more compact
\usepackage{titlesec} % Allows customization of titles
\usepackage{biblatex}
\usepackage{listings}
% \renewcommand\thesection{\Roman{section}} % Roman numerals for the sections
% \renewcommand\thesubsection{\roman{subsection}} % roman numerals for subsections
\titleformat{\section}[block]{\large\scshape\centering}{\thesection.}{1em}{} % Change the look of the section titles
\titleformat{\subsection}[block]{\large}{\thesubsection.}{1em}{} % Change the look of the section titles

\usepackage{fancyhdr} % Headers and footers
\pagestyle{fancy} % All pages have headers and footers
\fancyhead{} % Blank out the default header
% \fancyfoot[RO,LE]{\thepage} % Custom footer text

\usepackage{titling} % Customizing the title section
\addbibresource{bibliography.bib}

\usepackage{hyperref} % For hyperlinks in the PDF
\usepackage{url} % For hyperlinks in the PDF

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\setlength{\droptitle}{-4\baselineskip} % Move the title up

\pretitle{\begin{center}\Huge\bfseries} % Article title formatting
\posttitle{\end{center}} % Article title closing formatting
\title{Implementation and Performance Analysis of Collective MPI Operations using Pipelining} % Article title
\author{%
\textsc{Jakob Kuen} \\[1ex] % Your name
\normalsize TU Wien \\ % Your institution
\normalsize \href{mailto:e01630056@student.tuwien.ac.at}{e01630056@student.tuwien.ac.at} % Your email address
%\and % Uncomment if 2 authors are required, duplicate these 4 lines if more
%\textsc{Jane Smith}\thanks{Corresponding author} \\[1ex] % Second author's name
%\normalsize University of Utah \\ % Second author's institution
%\normalsize \href{mailto:jane@smith.com}{jane@smith.com} % Second author's email address
}
\date{\today} % Leave empty to omit a date
\renewcommand{\maketitlehookd}{}

%----------------------------------------------------------------------------------------

\begin{document}
\nocite{*}

% Print the title
\maketitle

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\section*{Notation}
In the interest of legibility I will use a simple shorthand notation when describing binary numbers in this report. Table \ref{tab:binary_shorthand} gives a brief summary through examples.

\begin{table}[h]
      \centering
      \begin{tabular}{ll}
            \toprule
            Shorthand & Full number \\
            \midrule
            10001    & 10001 \\
            $1_5$    & 11111  \\
            $10_4$   & 10000  \\
            $0_21_3$ & 00111  \\
            \bottomrule
            \label{tab:binary_shorthand}
      \end{tabular}
      \caption{Binary shorthand}
\end{table}

\section*{Binary tree representation}\label{sec:binary_tree}
In order to effectively construct and pipeline the required collective operations, it is helpful to organize involved processes into a complete binary tree structure. 

\begin{figure}
      \centering
      \begin{tikzpicture}
            \Tree[.07
                  [.03
                        [.01 00 02 ]
                        [.05 04 06 ]
                  ]
                  [.11
                        [.09 08 10 ]
                        [.13 12 14 ]
                  ]
            ]
      \end{tikzpicture}
      \caption{A complete binary tree with $2^4-1 = 15$ children}
      \label{fig:tree_inorder}
\end{figure}

Figure \ref{fig:tree_inorder} shows a complete binary tree with each node indexed through in-order traversal. All processes involved in the collective operation are assigned to a node in the tree, based on its rank within the communicator\footnote{This works assuming there are $p = 2^n-1 \:|\: n \in \mathbb{N}$ processes which exactly fill the tree. Special handling is required for other $p$, which will be described in Section \ref{sec:handling_incomplete}}. This process mapping has three benefits when implementing a collective operation:
\begin{itemize}
      \item The tree structure helps to organize communication between nodes. A reduction can be thought of as data travelling up from the leaves to the root nodes, a broadcast as the opposite.
      \item Reductions that are not commutative need to be processed in a way that preserves order. By reducing upwards in an in-order tree, this order is kept correctly.
      \item Relevant tree operations such as finding a node's parent or its children can be implemented efficiently using bitwise techniques.
\end{itemize}

\subsection{Bitwise tree operations}\label{sec:bitwise_tree_operations}
By construction of the in-order numbering, the index of a node is related to it's parent and child nodes. Figure \ref{fig:tree_inorder_binary} shows the same tree with its nodes in binary representation which illustrates how node properties can be read from its index. The following only describes how tree operations are performed, formal proofs are out of scope for this paper.

\begin{figure}
      \centering
      \begin{tikzpicture}
            \scriptsize
            \Tree[.0111
                  [.0011
                        [.0001 0000 0010 ]
                        [.0101 0100 0110 ]
                  ]
                  [.1011
                        [.1001 1000 1010 ]
                        [.1101 1100 1110 ]
                  ]
            ]
      \end{tikzpicture}
      \caption{Tree with binary numbering}
      \label{fig:tree_inorder_binary}
\end{figure}

\subsubsection{Node Depth}
A node's index has the form $...01_l$, where l is the layer the node is on. Here I define $layer := treeheight - depth - 1$. Since the treeheight is known, finding the depth of a node reduces to finding its layer which is given by the position of the first 0 in its index. This is implemented by taking the bitwise inverse of the index, and finding its least significant set bit using gcc's built-in \texttt{\_\_builtin\_ctz}.

\subsubsection{Node Parent}
Finding a nodes parent is slightly more complicated. Clearly, the parent is one layer higher up than the child. So the parent must have the form $...01_{l+1}$. What remains unclear is the left section of the index. However, simply setting the first $l+2$ bits of the node's index to $01_{l+1}$ already yields the parent index. Any bit at a position higher than $l+2$ relates to which subtree of the grandparent node node/parent are situated in. Since node and parent are always in the same subtree of the grandparent, these upper bits are the same for both.

\subsubsection{Node children}
A node at layer l has left and right subtrees, each with $2^l$ children in it. Again, the children must have the form $...01_{l-1}$. Furthermore, their bits starting from position $l+2$ must be identical to the parent. This leaves only the bit at position $l+1$ undefined, and setting it to either 0 or 1 yields the two children.

\begin{table}[h]
      \centering
      \begin{tabular}{ll}
            \toprule
            relation & index \\
            \midrule
            parent & $1\underline{011}$  \\
            base   & $10\underline{01}$  \\
            child 0 & $10\mathbf{0}\underline{0}$  \\
            child 1 & $10\mathbf{1}\underline{0}$  \\
            \bottomrule
      \end{tabular}
      \caption{Node relationships}
\end{table}

Using these operations each process can quickly determine its parent and child processes with which it will communicate.


\section{Exercise 1}
The objective of this exercise was to implement an MPI conforming \textit{Allreduce} \cite{mpi_allreduce} operation by decomposing it into a reduction and a broadcast stage. Both stages are based on a binary-tree approach, which will be described in the following subsections.

\subsection{Reduction}
In a reduction, each of the $p$ involved processors $p_i$ possesses one vector of data $d_i$. The reduction applies an operation to all of these vectors element-wise, reducing them to a single result. The vectors $d_i$ may be broken up into individual blocks, meaning processors may have to send multiple times to export all of their data. After completion, a single processor ends up with the final reduction result. Depending on the operations commutativity, the reduction must be performed in a way which keeps order of the operands.\\
With the binary tree set up, a reduction can now be formulated. The reduction is composed of individual rounds, during which any processes may send or receive from others. A process can at most send and receive once per round. For a simple case of $p=3$ processors, the algorithm should proceed as follows:

\begin{figure}
      \centering
      \begin{tikzpicture}
            \Tree[.1 0 2 ]
      \end{tikzpicture}
      \caption{Simple binary tree}
\end{figure}

\begin{enumerate}
      \item Node 1 receives the next unprocessed block of $d_0$ from its left child 0 and applies the reduction locally with its corresponding block of $d_1$
      \item Node 1 receives the next unprocessed block of $d_2$ from its right child 2 and applies the reduction locally with its corresponding block of $d_1$
      \item Repeat from step 1 until all blocks are have be processed
\end{enumerate}

Extending this algorithm for larger trees yields

\begin{enumerate}
      \item Each node receives a block from its left child, if that child has a block containing the reduction of all its children, then reduce locally
      \item Each node receives a block from its right child, if that child has a block containing the reduction of all its children, then reduce locally
      \item Each node that received left and right blocks now has a locally reduced block to send up to its parent 
      \item Repeat from step 1 until all blocks are have be processed up to the root node
\end{enumerate}

In the first step, only leaf nodes can send up, since they have no children from which they have to gather data to reduce. After two rounds, nodes in layer one have received data from all children and can send up to their parents. This continues up the tree until eventually the root node can receive blocks from its 2 parents. \\

To actually implement this approach, each processor needs to determine in which rounds in sends and/or receives - and where to/from. On a high level, this is accomplished using constraints. Each process starts at round 0, and determines if the conditions are met for it to send/receive - in which case it will call MPI\_Send/MPI\_Recv. Otherwise it will simply move on to the next round. If the conditions are defined correctly, all send/recv calls will line up with the other processors and the reduction proceeds as planned. The algorithm split up into two sections, one determining if the process should send, and the other if it should receive. Listing \ref{cod:constraints} gives a high-level view of the structure and constraints.

\begin{lstlisting}[label=cod:constraints,language=C++,caption=Constraint based implementation,captionpos=b]
int sentBlocks = 0
int recvdBlocks = 0
int node, parent, 
    left, right, layer
int blockcount
for round in rounds:
      bool shouldSend = ...
      bool shouldReceive = ...

      if shouldSend: 
            send(...)
            sentBlocks++
      if shouldReceive: 
            recv(...)
            reduce_local(...)
            recvdBlocks++

\end{lstlisting}

\texttt{sentBlocks} and \texttt{recvdBlocks} keep count of how many blocks have been sent/received by each node to determine which blocks will be sent/received next. Each node also knows its rank (=\texttt{node}), \texttt{parent}, \texttt{left} and \texttt{right} child nodes, and the \texttt{layer} it is on. These are computed as described in Section \ref{sec:binary_tree}. \texttt{blockcount} is the number of blocks the  vector is split up into. What is left now is to define how shouldSend and shouldReceive are determined. This may initially seem like a complicated task, but it can be broken down into a few simpler conditions which need to be met. 

\subsubsection{Sending}
Starting with shouldSend, the following conditions arise:

\begin{itemize}
      \item A node has blocks to send only if has received at least the first blocks from each its children, so a total of 2 received blocks. However, nodes in the first layer have no children and nothing to receive, so they can start sending immediately.\\\\
      \texttt{recvdBlocks > 2 || layer == 0}\\
      \item As long as a node has sent less than \texttt{blockcount} blocks, it has more blocks left to send. \\\\
      \texttt{sentBlocks != blockcount}\\
      \item A left child only sends up to the parent on even rounds, a right child only on odd ones. Determining whether a node is left or right of its parent can simply be determined by comparing indices. \\\\
      \texttt{parent<node \&\& round\%2 == 1 ||} \\
      \texttt{parent>node \&\& round\%2 == 0}\\
      \item A node should only send if it has a parent \\
      \texttt{parent != -1}
\end{itemize}

A node only sends if all of these conditions are met. 

\subsubsection{Receiving}
The same can be done to arrive at conditions for a node to receive data. In general, a node should receive if and only if one of its children is sending, so the logic should be quite similar.

\begin{itemize}
      \item A node should only receive if its children already have blocks to send up. Every two rounds, blocks move up one layer, so the first block arrive to the layer below in 2*(layer-1) rounds. \\\\
      \texttt{round/2 >= layer - 1}\\
      \item For each block, a node receives 2 corresponding blocks from its children. So in total, it needs to receive no more than blockcount*2 blocks. \\\\
      \texttt{recvdblocks/2 != blockcount}\\
      \item Leaf nodes have no children to receive from, which is indicated by \texttt{left/right = -1}. \\\\
      \texttt{child != -1}
\end{itemize}

\texttt{child} is simply the left or right child, depending on if the current round is even or odd: \texttt{child = round \% 2 == 0 ? left : right}. With these conditions established, each process can run through the rounds, and determine if it needs to send/receive until all rounds are completed. In total, \texttt{2*(treeheight + blockcount)} rounds are needed until the last block has moved from leaf to root. Since send/receive calls are blocking, rounds are implicitly synchronized and no node can get ahead of the rest. After all rounds are completed, the resulting reduction will be at the root node/process of the tree.

\subsection{Broadcast}
After the reduction is complete, a broadcast is necessary to move the result from the root process to all other processes. The implementation is analogous to the reduction, except that data flow is reversed - data now travels down from the root, until all blocks have reached the leaf nodes. The conditions for sending/receiving are therefore reversed.

\subsubsection{Sending}
\begin{itemize}
      \item A node has blocks to send only if has received at least the first blocks from its parent However, the root node has no parent and nothing to receive, so it can start sending immediately.\\\\
      \texttt{recvdblocks >= 1 || \\ layer == treeheight}\\
      \item As long as a node has sent less than \texttt{blockcount/2} blocks (since each block gets sent once per child), it has more blocks left to send. \\\\
      \texttt{sentblocks/2 != blockcount}\\
      \item Leaf nodes have no children to send to, which is indicated by \texttt{left = right = -1}. \\\\
      \texttt{child != -1}
\end{itemize}

\subsubsection{Receiving}
\begin{itemize}
      \item A node that is a left child should only receive from its parent on even rounds, and a right child only on odd rounds \\\\
      \texttt{parent<node \&\& round\%2 == 1 || \\parent>node \&\& round\%2 == 0}\\
      \item A node should only receive \texttt{blockcount} nodes, and not any more. \\\\
      \texttt{recvdblocks != blockcount}\\
      \item A node only receives if it has a parent that is ready to send this round. \\\\
      \texttt{parent != -1 \&\& \\round/2 >= (treeheight-depth(parent))}\\
\end{itemize}

Each process proceeds exactly as with the reduction by iteration over all rounds, and issuing the send/receive operations it has determined from these conditions.

\subsection{Handling incomplete trees}\label{sec:handling_incomplete}
So far the assumption has been that the amount of processes involved in the operation neatly fit into a complete binary tree. Extending the algorithm to work for an arbitrary amount of processes requires a more intricate constructions. The implementation relies heavily on having a complete in-order numbering across the nodes to compute parent and child nodes - to preserve these properties, the \texttt{p} processes are distributed onto the smallest complete binary tree with $p \le n$ nodes as shown in Figure \ref{fig:tree_missing_processes}. By construction there are enough processes to assign to every non-leaf node and the lowest layer of the tree is filled up left to right until there are no more processes left over. Any remaining leaf-nodes on the right do not have a process assigned to them \textit{(virtual nodes)}. This ensure the tree stays reasonably balanced. Process ranks are determined by traversing this sub-tree in-order as shown in Figure \ref{fig:tree_process_ranks}.

\begin{figure}
      \centering
      \begin{tikzpicture}
            \Tree[.07
                  [.03
                        [.01 00 02 ]
                        [.05 04 \sout{06} ]
                  ]
                  [.11
                        [.09 \sout{08} \sout{10} ]
                        [.13 \sout{12} \sout{14} ]
                  ]
            ]
      \end{tikzpicture}
      \caption{Nodes on a complete binary tree containing only 10 processes}
      \label{fig:tree_missing_processes}
\end{figure}

\begin{figure}
      \centering
      \begin{tikzpicture}
            \Tree[.06
                  [.03
                        [.01 00 02 ]
                        [.05 04 -- ]
                  ]
                  [.08
                        [.07 -- -- ]
                        [.09 -- -- ]
                  ]
            ]
      \end{tikzpicture}
      \caption{Ranks assigned to each node in the complete tree}
      \label{fig:tree_process_ranks}
\end{figure}

The idea is now to find an efficient way to convert back and forth between process rank and the corresponding node in the complete tree. A few key observations:
\begin{itemize}
      \item Only nodes with and even index can be virtual
      \item The rank of a process is always smaller or equal to its node index
      \item The difference between a process rank and its node index is exactly the amount of virtual nodes with an index lower than the process's node index
\end{itemize}

The indices of virtual nodes can be easily calculated from the amount of processes involved in the operation. Converting from any rank to node index, it suffices to iteratively count how many virtual nodes have a lower index and add that count to the process rank.
\begin{lstlisting}[language=C++,caption=Converting rank to node index,captionpos=b]
int skips = 0
while(rank+skips>=overshoot+skips*2)
      skips++
node = rank + skips
\end{lstlisting}

Here, \texttt{overshoot} is the index of the first virtual node, i.e. 6 for this example.
Converting back is simpler as no iteration is needed. The amount of virtual nodes with a lower index is simply the amount of even nodes larger or equal to \texttt{overshoot}. Subtracting this count from the node index results in the mapped process rank. \\

\begin{lstlisting}[language=C++,caption=Converting node index to rank,captionpos=b]
int skipped = 
      max(0,(node-overshoot+1)/2);
return node - skipped;
\end{lstlisting}

The allreduce implementation now only needs to be extended slightly, by first converting each process rank to its node index and calculating parent/child nodes based on that. Child and parent node indices are converted back to process ranks, leaving each process with the ranks of the processes it will communicate with. This requires no additional network communication.

\subsection{Performance Modelling with the Pipeline Lemma}
The pipeline lemma can be used to model the running time of a pipelined algorithm, using a linear transmission cost model. The lemma states that given
\begin{itemize}
      \item k := maximum latency in rounds until a process receives the first block
      \item s := number of rounds between receiving new blocks
      \item m := size of input vectors
      \item $\alpha,\beta$ := linear transmission cost model
\end{itemize}
the performance is expressed by
\begin{equation}
      (k-s)\alpha + 2\sqrt{s(k-s)\alpha\beta m} + s\beta m
\end{equation}
Both stages of the allreduce implementation (reduce and broadcast) exhibit a latency $k=2*log(p)$ where p is the number of processors and $s=2$. Summing the running time for both stages yields
\begin{equation}
      2(4log(p)-4\alpha + 2\sqrt{(4log(p)-4)\alpha\beta m} + 2\beta m)
\end{equation}
Using the pipeline lemma one can also determine the optimal block count $M$ using the identity 
\begin{equation}
      M = \sqrt{(k-s)\frac{\beta m}{s}\alpha}
\end{equation}
\begin{equation}
      = \sqrt{(2log(p)-2)\frac{\beta m}{2}\alpha}
\end{equation}

\section{Exercise 2}
This second exercise aims to extend the algorithm by combining the reduction and broadcast into a single stage, running both operations at once. Furthermore the single binary tree is replace by two binary trees connected at the root, as described in the accompanying paper \cite{traeff2021dualroot}. Figure \ref{fig:dual_rooted_tree} shows the tree structure.

\begin{figure}
      \centering
      \begin{tikzpicture}
            \Tree[
                  \edge[dashed,draw=gray];[.03
                        [.01 00 02 ]
                        [.04 -- -- ]
                  ]
                  \edge[dashed,draw=gray];[.08
                        [.06 05 07 ]
                        [.09 -- -- ]
                  ]
            ];
      \end{tikzpicture}
      \caption{Doubly-rooted binary tree process ranks}
      \label{fig:dual_rooted_tree}
\end{figure}

Since the algorithm is already setup to work based on constraints, it is relatively trivial to combine both stages into one. Each process checks its constraints for both reduction and broadcast, and does either or both of them per round. The constraints only have to be adapted slightly, e.g. the broadcast stage can only begin once the first block of values has reached the dual-root. However these changes are minimal. Furthermore, due to the new tree structure, the process of mapping processes to nodes has to be adapted. In principle the mapping is unchanged and just performed for two trees instead of one. This is implemented by splitting the processes into 2 equally sized halves (for an odd number of processors, the left tree will have one additional process). The left tree can be mapped the same as for the first exercise, as the in-order numbers has the same properties. Observing that the right subtree is an exact copy of the left tree, with each node index incremented by \texttt{process\_count/2} allows us to simply subtract this offset from the process rank which yields the corresponding process in the left tree. Now children and parents can be calculated as before. This results in parent and child nodes in the left subtree. Adding the offset back onto these process ranks again yields the processes of the right subtree. This process is shown in Figure \ref{fig:dual_tree_translation}.

\begin{figure}
      \centering
      \begin{tikzpicture}
            \Tree[
                  \edge[dashed,draw=gray];[. \node(03){03};
                        [. \node(01){01}; \node(00){00}; \node(02){02}; ]
                        [.04 -- -- ]
                  ]
                  \edge[dashed,draw=gray];[. \node(08){08};
                        [. \node(06){06}; \node(05){05}; \node(07){07}; ]
                        [.09 -- -- ]
                  ]
            ];
            \draw[red,->] (06) to [out=130,in=50] node [above] {$-5$} (01);
            \draw[blue,->] (01) to [out=210,in=90] (00);
            \draw[blue,->] (01) to [out=-30,in=90] (02);
            \draw[blue,->] (01) to [out=90,in=180] (03);
            \draw[red,->] (00) to [out=-50,in=-130] node [below] {$+5$} (05);
            \draw[red,->] (02) to [out=50,in=130] node [above] {$+5$} (07);
            \draw[red,->] (03) to [out=50,in=130] node [above] {$+5$} (08);
      \end{tikzpicture}
      \caption{Process of finding parent and children for a node in the right sub tree}
      \label{fig:dual_tree_translation}
\end{figure}

Some extra care has to be taken to account for an odd number of processors, and making sure all calculated processes actually exist.

\subsection{Adjustments to the Pipeline Model}
With this adapted implementation, the parameters for the pipeline model have changed. Most notable, there is now only a single pipeline instead of two.
\begin{itemize}
      \item k := maximum latency in rounds until a process receives the first block
      \item s := number of rounds between receiving new blocks
      \item m := size of input vectors
      \item $\alpha,\beta$ := linear transmission cost model
\end{itemize}
the performance is expressed by
\begin{equation}
      (k-s)\alpha + 2\sqrt{s(k-s)\alpha\beta m} + s\beta m
\end{equation}
Both stages of the allreduce implementation (reduce and broadcast) exhibit a latency $k=2*log(p)$ where p is the number of processors and $s=2$. Summing the running time for both stages yields
\begin{equation}
      2(4log(p)-4\alpha + 2\sqrt{(4log(p)-4)\alpha\beta m} + 2\beta m)
\end{equation}
Using the pipeline lemma one can also determine the optimal block count $M$ using the identity 
\begin{equation}
      M = \sqrt{(k-s)\frac{\beta m}{s}\alpha}
\end{equation}
\begin{equation}
      = \sqrt{(2log(p)-2)\frac{\beta m}{2}\alpha}
\end{equation}

\section{Correctness}
To verify the correctness of the algorithms, the implementations were tested against the MPI\_Allreduce function, ensuring the same result for all combinations of various parameter settings. Each processes' vector elements were set to $v[i] = ((i + process\_rank) \% 10) + 1$

\begin{table}[h]
      \centering
      \begin{tabular}{ll}
            \toprule
            Parameter & Values \\
            \midrule
            vectorsize   & 1,2,...,9999,10000 \\
            blocksize    & 1,2,...,9999,10000  \\
            processes    & 2,3,...,9,10  \\
            \bottomrule
      \end{tabular}
      \caption{Parameter values}
\end{table}
  
\printbibliography

%----------------------------------------------------------------------------------------

\end{document}
